{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install numpy tqdm scikit-learn tensorflow keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 06:48:26.592173: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733813306.661981   67935 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733813306.684242   67935 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-10 06:48:26.843226: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Import packages needed\n",
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Lambda, Dense\n",
    "from keras import Model\n",
    "from keras.models import load_model, Sequential\n",
    "from keras.ops import cast, maximum, square\n",
    "from keras.metrics import binary_accuracy\n",
    "from keras.applications import ResNet50\n",
    "from keras import Input\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for reading all the image from the dataset folder\n",
    "def get_data():\n",
    "    # read all the folders\n",
    "    data_path = \"../../dataset/Musinsa_dataset\"\n",
    "    folders = os.listdir(data_path)\n",
    "\n",
    "    # read all the images inside the folders\n",
    "    style2index = []\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i in range(len(folders)):\n",
    "        folder = folders[i]\n",
    "        folder_path = f\"{data_path}/{folder}\"\n",
    "\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        files = os.listdir(folder_path)\n",
    "        print(folder)\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for file in tqdm(files):\n",
    "            try:\n",
    "                # read the image\n",
    "                image = cv2.imread(f\"{folder_path}/{file}\")\n",
    "                image = cv2.resize(image, (224, 224))\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                image = image.astype(np.float32) / 255.0\n",
    "\n",
    "                images.append(image)\n",
    "                labels.append(i)\n",
    "                count += 1\n",
    "                if count >= 2000:\n",
    "                    break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading image {file}: {e}\")\n",
    "        style2index.append({folder: i})\n",
    "\n",
    "    return images, labels, style2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1642/1642 [00:02<00:00, 804.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1780/1780 [00:02<00:00, 837.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cityboy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1999/2605 [00:02<00:00, 796.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Casual\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 1999/2870 [00:02<00:01, 798.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1770/1770 [00:02<00:00, 826.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preppy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1355/1355 [00:01<00:00, 813.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workwear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 1999/2556 [00:02<00:00, 787.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 1999/2670 [00:02<00:00, 780.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Street\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1223/1223 [00:01<00:00, 817.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gorpcore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 1999/2631 [00:02<00:00, 777.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sporty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 1999/2378 [00:02<00:00, 814.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Romantic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1795/1795 [00:02<00:00, 815.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Girlish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1783/1783 [00:02<00:00, 819.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23348 23348\n",
      "[{'Classic': 1}, {'Chic': 2}, {'Cityboy': 3}, {'Casual': 4}, {'Minimal': 5}, {'Preppy': 6}, {'Workwear': 7}, {'Retro': 8}, {'Street': 9}, {'Gorpcore': 10}, {'Sporty': 11}, {'Romantic': 12}, {'Girlish': 13}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "image, labels, style2index = get_data()\n",
    "print(len(image), len(labels))\n",
    "print(style2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: 18678, 18678\n",
      "test set size: 4670, 4670\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(image, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"train set size: {len(X_train)}, {len(y_train)}\")\n",
    "print(f\"test set size: {len(X_test)}, {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18678, 224, 224, 3) (4670, 224, 224, 3) (18678,) (4670,)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_train = np.array(y_train)\n",
    "Y_test = np.array(y_test)\n",
    "\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pair(X, y):\n",
    "    \"\"\"\n",
    "        For contrastive learning, we need the dataset in pair.\n",
    "        There should exist \n",
    "        Input: X(image), y(label)\n",
    "        Output: X_pairs(image pair), y_pairs(label pair)\n",
    "    \"\"\"\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    X_pairs = []\n",
    "    y_pairs = []\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        digit = y[i]\n",
    "\n",
    "        positive_digit_index = np.random.choice(np.where(y == digit)[0])\n",
    "        X_pairs.append([X[i], X[positive_digit_index]])\n",
    "        y_pairs.append([0])\n",
    "\n",
    "        negative_digit_index = np.random.choice(np.where(y!=digit)[0])\n",
    "        X_pairs.append([X[i], X[negative_digit_index]])\n",
    "        y_pairs.append([1])\n",
    "\n",
    "    indices = np.arange(len(X_pairs))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    return np.array(X_pairs)[indices], np.array(y_pairs)[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733813342.380022   67935 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22456 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:61:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_pairs shape:  (37356, 2, 224, 224, 3)\n",
      "X_test_pairs shape:  (9340, 2, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    X_train_pairs, Y_train_pairs = generate_pair(X_train, y_train)\n",
    "    X_test_pairs, Y_test_pairs = generate_pair(X_test, y_test)\n",
    "\n",
    "    print(\"X_train_pairs shape: \", X_train_pairs.shape)\n",
    "    print(\"X_test_pairs shape: \", X_test_pairs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Physical GPUs:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Physical GPUs: \", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.debugging.set_log_device_placement(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet based model\n",
    "\n",
    "Using feature extraction part of pretrained ResNet model, one fc layer will be added on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use backbone of ResNet50\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    input1 = Input(shape=(224,224,3,))\n",
    "    input2 = Input(shape=(224,224,3,))\n",
    "\n",
    "    base_model = ResNet50(weights=\"imagenet\", include_top=True)\n",
    "\n",
    "    network = Sequential(\n",
    "        [\n",
    "            Input(shape=(224, 224, 3)),\n",
    "            base_model,\n",
    "            Dense(128, activation=None)\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    twin1 = network(input1)\n",
    "    twin2 = network(input2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(twins):\n",
    "    twin1_output, twin2_output = twins\n",
    "    twin1_norm = tf.linalg.l2_normalize(twin1_output, axis=1)\n",
    "    twin2_norm = tf.linalg.l2_normalize(twin2_output, axis=1)\n",
    "\n",
    "    cosine_similarity = twin1_norm * twin2_norm  # Element-wise multiplication\n",
    "    cosine_similarity = tf.reduce_sum(cosine_similarity, axis=1, keepdims=True)\n",
    "\n",
    "    return (1 - cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    distance = Lambda(cosine_distance)([twin1, twin2])\n",
    "    model = Model(inputs=[input1, input2], outputs=distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(y, d):\n",
    "    \"\"\"\n",
    "    Compute the contrastive loss introduced by Yann LeCun et al. in the paper\n",
    "    \"Dimensionality Reduction by Learning an Invariant Mapping.\"\n",
    "    \"\"\"\n",
    "\n",
    "    margin = 1\n",
    "    y = cast(y, d.dtype)\n",
    "\n",
    "    loss = (1 - y) / 2 * square(d) + y / 2 * square(maximum(0.0, margin - d))\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    model.compile(loss=contrastive_loss, optimizer=\"adam\", metrics=[binary_accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 06:49:28.550243: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 22492495872 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    tf.debugging.set_log_device_placement(True)\n",
    "    history = model.fit(\n",
    "        x=[X_train_pairs[:, 0], X_train_pairs[:, 1]],\n",
    "        y=Y_train_pairs[:],\n",
    "        validation_data=([X_test_pairs[:, 0], X_test_pairs[:, 1]], Y_test_pairs[:]),\n",
    "        batch_size=8,\n",
    "        epochs=5,\n",
    "    )\n",
    "    tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    plt.plot(history.history[\"loss\"])\n",
    "    plt.plot(history.history[\"val_loss\"])\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"val\"], loc=\"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    predictions = model.predict([X_test_pairs[:, 0], X_test_pairs[:, 1]]) >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    print(model.layers)\n",
    "    print(model.layers[2].input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = image.astype(np.float32) / 255.0\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    embedding_model = model.layers[2]\n",
    "    print(embedding_model)\n",
    "\n",
    "    image_path = \"../../dataset/Musinsa_dataset/Cityboy/snap_card_1305697549538040667.jpg\"\n",
    "    image = load_image(image_path)\n",
    "    embedding = embedding_model.predict(image.reshape(1, 224, 224, 3))\n",
    "\n",
    "    print(embedding.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    # Save the model\n",
    "    embedding_model = Model(inputs=input1, outputs=twin1)\n",
    "\n",
    "    embedding_model.save(\"embedding_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    # Load the model\n",
    "    loaded_model = load_model(\"embedding_model.h5\")\n",
    "\n",
    "    image_path = \"../../dataset/Musinsa_dataset/Cityboy/snap_card_1305697549538040667.jpg\"\n",
    "    image = load_image(image_path)\n",
    "\n",
    "    embedding = loaded_model.predict(image.reshape(1, 224, 224, 3))\n",
    "\n",
    "    print(\"Generated embedding: \", embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
